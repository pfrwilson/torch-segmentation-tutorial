{"cells":[{"cell_type":"markdown","id":"f4d2d605","metadata":{"id":"f4d2d605"},"source":["# Training a 3D UNet wih MONAI\n","\n"]},{"cell_type":"markdown","source":["# Part 1 - Basic training loop"],"metadata":{"id":"gTWDhh6gIDzI"},"id":"gTWDhh6gIDzI"},{"cell_type":"markdown","source":["## Set up environment"],"metadata":{"id":"zJ0GYiznpQjd"},"id":"zJ0GYiznpQjd"},{"cell_type":"code","execution_count":null,"id":"823c066e","metadata":{"id":"823c066e"},"outputs":[],"source":["!pip -q install \"monai-weekly\" \"torch>=2.1\" \"tqdm\""]},{"cell_type":"code","execution_count":null,"id":"538b2df8","metadata":{"id":"538b2df8"},"outputs":[],"source":["import monai, torch, os, tempfile, matplotlib.pyplot as plt\n","from monai.data import DataLoader, CacheDataset\n","from monai.networks.nets import UNet\n","from monai.losses import DiceLoss\n","from monai.metrics import DiceMetric"]},{"cell_type":"markdown","source":["## Download the dataset"],"metadata":{"id":"RzquBe3ppUt0"},"id":"RzquBe3ppUt0"},{"cell_type":"code","execution_count":null,"id":"6de70f40","metadata":{"id":"6de70f40"},"outputs":[],"source":["\n","from monai.apps import download_and_extract\n","root_dir = 'data'\n","resource = 'https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar'\n","compressed_file = os.path.join(root_dir, \"spleen.tar\")\n","download_and_extract(resource, compressed_file, root_dir)\n"]},{"cell_type":"markdown","source":["## Prepare the dataset"],"metadata":{"id":"juwbkqtjpXDd"},"id":"juwbkqtjpXDd"},{"cell_type":"code","source":["from monai.data import Dataset\n","from glob import glob\n","images = sorted(glob(os.path.join(root_dir,\"Task09_Spleen/imagesTr/*.nii.gz\")))\n","labels = sorted(glob(os.path.join(root_dir,\"Task09_Spleen/labelsTr/*.nii.gz\")))\n","train_files = [{\"image\":img, \"label\":lbl} for img,lbl in zip(images,labels)]\n","\n","print(f\"Number of files: {len(train_files)}\")\n","print(train_files[0])\n"],"metadata":{"id":"Mvl6ztcDpJ5w"},"id":"Mvl6ztcDpJ5w","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from monai import transforms as T\n","\n","def make_transform(n_pixels=64):\n","    # Steps to transform the file information to model inputs:\n","\n","    transforms = []\n","\n","    # step 1: load the data, nii.gz format to tensor\n","    transforms.append(\n","        T.LoadImaged(keys=['image', 'label'])\n","    )\n","\n","    # step 2: Add an extra \"channel\" dimension (pytorch/monai convention)\n","    transforms.append(\n","        T.EnsureChannelFirstd(keys=['image', 'label'])\n","    )\n","\n","    # step 3: Resize the data to a uniform size\n","    transforms.append(\n","        T.ResizeD(keys=['image', 'label'], spatial_size=(n_pixels, n_pixels, n_pixels//2), mode=['bilinear', 'nearest'])\n","    )\n","\n","    # step 4: rescale the image intenisty between 0 and 1\n","    transforms.append(T.ScaleIntensityD(keys=['image']))\n","\n","    transform = T.Compose(transforms)\n","    return transform\n","\n","\n","transform = make_transform(256)"],"metadata":{"id":"Xx2pAvQkqDqM"},"id":"Xx2pAvQkqDqM","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# look at the output\n","data = transform(train_files[0])\n","fig, ax = plt.subplots(1, 2)\n","ax[0].imshow(data['image'][0, ..., 75])\n","ax[1].imshow(data['image'][0, ..., 75])\n","ax[1].imshow(data['label'][0, ..., 75], alpha=0.5)\n","fig.tight_layout()\n","\n","image = data['image']\n","label = data['label']\n","print(f\"pixel mean: {image.mean()}\")\n","print(f\"pixel std: {image.std()}\")\n","print(f\"Image shape: {image.shape}\")\n","print(f\"Label shape: {label.shape}\")\n","print(f\"Label values: {torch.unique(label)}\")"],"metadata":{"id":"aYJY-yrjsqVY"},"id":"aYJY-yrjsqVY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create dataset and dataloader\n","train_ds = train_dataset = monai.data.CacheDataset(train_files, transform=make_transform(64), cache_rate=1)\n","train_loader = torch.utils.data.DataLoader(train_ds, batch_size=4, shuffle=True)\n","\n","batch = next(iter(train_loader))\n","image = batch['image']\n","label = batch['label']\n","print(f'Image shape: {image.shape}')\n","print(f'Label shape: {label.shape}')\n"],"metadata":{"id":"dyEuuXUOusxk"},"id":"dyEuuXUOusxk","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prepare And Train the Model"],"metadata":{"id":"u8oBRBgavUZQ"},"id":"u8oBRBgavUZQ"},{"cell_type":"code","source":["# define a unet using monai\n","\n","def get_model():\n","    return UNet(spatial_dims=3, in_channels=1, out_channels=2,\n","             channels=(16,32,64,128), strides=(2,2,2),\n","             num_res_units=2)\n","\n","model = get_model()\n","\n","n_params = sum(p.numel() for p in model.parameters())\n","print(f\"Model has {n_params} parameters.\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # device to run calculations - \"cuda\" means gpu\n","print(f\"Using device {device}\")\n","model.to(device) # convert model to the correct device\n","loss_fn = DiceLoss(to_onehot_y=True, softmax=True)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"],"metadata":{"id":"KzT1WPO-vfqh"},"id":"KzT1WPO-vfqh","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"218204a3","metadata":{"id":"218204a3"},"outputs":[],"source":["from tqdm import tqdm\n","from collections import defaultdict\n","\n","\n","def run_training(model, optimizer, loss_fn, train_dataloader, val_dataloader=None, max_epochs=100):\n","\n","    history = defaultdict(list)\n","\n","    for epoch in range(max_epochs):\n","        model.train()\n","        epoch_loss = 0\n","        for batch_data in tqdm(train_dataloader, desc=f\"Epoch {epoch}\", leave=False):\n","            inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = loss_fn(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += loss.item()\n","        print(f\"Epoch {epoch+1}, avg loss: {epoch_loss/len(train_dataloader):.4f}\")\n","        history['train_loss'].append(epoch_loss/len(train_dataloader))\n","\n","        if val_dataloader is not None:\n","            model.eval()\n","            epoch_loss = 0\n","            with torch.no_grad():\n","                for batch_data in tqdm(val_dataloader, desc=f\"Epoch {epoch}\", leave=False):\n","                    inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n","                    outputs = model(inputs)\n","                    loss = loss_fn(outputs, labels)\n","                    epoch_loss += loss.item()\n","            history['val_loss'].append(epoch_loss/len(val_dataloader))\n","\n","    return history\n","\n","\n","history = run_training(model, optimizer, loss_fn, train_loader, max_epochs=30)\n","\n","key = 'loss'\n","for name, metrics in history.items():\n","    if key not in name:\n","        continue\n","    plt.plot(metrics, label=name)\n","plt.legend()\n"]},{"cell_type":"code","execution_count":null,"id":"7e1af18c","metadata":{"id":"7e1af18c"},"outputs":[],"source":["# test inference\n","\n","model.eval()\n","with torch.no_grad():\n","    sample = train_ds[0]\n","    input_volume = sample[\"image\"].unsqueeze(0).to(device)\n","    pred = torch.argmax(model(input_volume), dim=1).cpu()[0]\n","\n","import numpy as np, matplotlib.pyplot as plt\n","mid_slice = pred.shape[-1]//2\n","plt.figure(figsize=(12,4))\n","plt.subplot(1,3,1); plt.imshow(input_volume.cpu()[0,0,:, :, mid_slice], cmap='gray'); plt.title('Image'); plt.axis('off')\n","plt.subplot(1,3,2); plt.imshow(sample[\"label\"][0, :, :, mid_slice], cmap='gray'); plt.title('Ground truth'); plt.axis('off')\n","plt.subplot(1,3,3); plt.imshow(pred[:, :, mid_slice], cmap='gray'); plt.title('Prediction'); plt.axis('off')\n","plt.show()\n"]},{"cell_type":"markdown","source":["# Part 2 - Monitoring Model Performance"],"metadata":{"id":"gi2eCW-THcJ8"},"id":"gi2eCW-THcJ8"},{"cell_type":"markdown","source":["Objectives:\n","- Use metrics to measure model performance\n","- Use cross validation to test for overfitting\n","- Use techniques to mitigate overfitting"],"metadata":{"id":"0KzG58YaIef0"},"id":"0KzG58YaIef0"},{"cell_type":"markdown","source":["Step 1: implement the dice metric. Hint: use the monai implementation https://docs.monai.io/en/stable/metrics.html#mean-dice and read its documentation. Incorporate it into the training loop defined above to get the new training loop."],"metadata":{"id":"-wQ6bgPBJnv6"},"id":"-wQ6bgPBJnv6"},{"cell_type":"code","source":["# TODO Implement this function using MONAI dice metric and the previously defined training function\n","def run_training_with_dice(model, optimizer, loss_fn, train_dataloader, val_dataloader=None, max_epochs=100):\n","    \"\"\"\n","    Implements a training loop that includes the dice metric.\n","    \"\"\"\n","    return run_training(model, optimizer, loss_fn, train_dataloader, val_dataloader, max_epochs) # placeholder\n"],"metadata":{"id":"AOSaqD41IL0I"},"id":"AOSaqD41IL0I","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = get_model()\n","\n","n_params = sum(p.numel() for p in model.parameters())\n","print(f\"Model has {n_params} parameters.\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # device to run calculations - \"cuda\" means gpu\n","print(f\"Using device {device}\")\n","model.to(device) # convert model to the correct device\n","loss_fn = DiceLoss(to_onehot_y=True, softmax=True)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n","\n","history = run_training_with_dice(model, optimizer, loss_fn, train_loader, max_epochs=30)\n","\n","key = 'loss'\n","for name, metrics in history.items():\n","    if key not in name:\n","        continue\n","    plt.plot(metrics, label=name)\n","plt.legend()\n","\n","plt.figure()\n","key = 'dice'\n","for name, metrics in history.items():\n","    if key not in name:\n","        continue\n","    plt.plot(metrics, label=name)\n","plt.legend()"],"metadata":{"id":"fucKrA7oQ3-u"},"id":"fucKrA7oQ3-u","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Step 2. Because we don't have a validation set yet, we don't know how well the model will generalize to new data. It could be overfitting to the training set! Create a validation set and run the training loop again. Compare the validation metrics to the training metrics. If the training loss is lower than the validation loss or the training dice is higher than the validation dice, this indicates overfitting."],"metadata":{"id":"ABQEg41IM_Lr"},"id":"ABQEg41IM_Lr"},{"cell_type":"code","source":["# Helpful demo: sklearn train_test_split function\n","# sklearn train_test_split demo\n","import sklearn\n","new_train_files, val_files = sklearn.model_selection.train_test_split(train_files)\n","\n","print(len(new_train_files))\n","print(new_train_files)\n","print(len(val_files))\n","print(val_files)"],"metadata":{"id":"OvrF-5dSOYZ0"},"id":"OvrF-5dSOYZ0","execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_train_loader = None\n","val_loader = None\n","# TODO - implement the validation loader. Hint: use the sklearn train_test_split function, then follow the \"Prepare dataset\"\n","# recipe with the two different sets of files to create two datasets and dataloaders."],"metadata":{"id":"6n4PyRIXMaHw"},"id":"6n4PyRIXMaHw","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run the training again with the validation loader. We want to improve the validation metrics (lower the validation loss and increase the validation dice) as much as possible while avoiding overfitting. When did overfitting occur? What were the best validation metrics?"],"metadata":{"id":"7_Hb-IlsRVUt"},"id":"7_Hb-IlsRVUt"},{"cell_type":"code","source":["model = get_model()\n","\n","n_params = sum(p.numel() for p in model.parameters())\n","print(f\"Model has {n_params} parameters.\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # device to run calculations - \"cuda\" means gpu\n","print(f\"Using device {device}\")\n","model.to(device) # convert model to the correct device\n","loss_fn = DiceLoss(to_onehot_y=True, softmax=True)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n","\n","history = run_training_with_dice(model, optimizer, loss_fn, new_train_loader, val_dataloader=val_loader, max_epochs=100)\n","\n","key = 'loss'\n","for name, metrics in history.items():\n","    if key not in name:\n","        continue\n","    plt.plot(metrics, label=name)\n","plt.legend()\n","\n","plt.figure()\n","key = 'dice'\n","for name, metrics in history.items():\n","    if key not in name:\n","        continue\n","    plt.plot(metrics, label=name)\n","plt.legend()\n"],"metadata":{"id":"Q0pOglenN_wZ"},"id":"Q0pOglenN_wZ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Step 3. Mitigating overfitting\n","\n","You are now free to experiment with modifying any part of the training pipeline. The goal is to reduce overfitting and improve the best validation dice. Suggestions and hints are outlined below."],"metadata":{"id":"TtCtWpvfTDXE"},"id":"TtCtWpvfTDXE"},{"cell_type":"code","source":["# Suggestion 1 - Modifying the model architecture.\n","\n","# read the monai documentation about UNet and edit the model configuration and experiment with the results.\n","# feel free to copy the documentation into a language model for advice on which configuration changes could mitigate overfitting!\n","def get_model():\n","    model = UNet(spatial_dims=3, in_channels=1, out_channels=2,\n","                channels=(16,32,64,128), strides=(2,2,2),\n","                num_res_units=2)\n","    return model"],"metadata":{"id":"AJT_YcHYTZe5"},"id":"AJT_YcHYTZe5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Suggestion 2 - Modifying the optimizer.\n","\n","# read the documentation about torch.optim.AdamW with the help of a language model. See if configuration changes could mitigate overfitting to improve performance\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"],"metadata":{"id":"ly9jrDoPUCTn"},"id":"ly9jrDoPUCTn","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Suggestion 3 - Modifying the data pipeline\n","\n","\n","# Data augmentation is a common technique to reduce overfitting by creating more variations in the data being used to train the model.\n","# Read the monai documentation for transforms such as https://docs.monai.io/en/1.3.0/transforms.html#randadjustcontrastd and https://docs.monai.io/en/1.3.0/transforms.html#randcoarseshuffled\n","# to see if adding these into the data pipeline can improve outcomes.\n","# ! WARNING ! be sure to disable them when you are creating the transform for the validation set by setting `is_train=False`\n","\n","def make_transform(n_pixels=64, is_train=True):\n","    # Steps to transform the file information to model inputs:\n","\n","    transforms = []\n","\n","    # step 1: load the data, nii.gz format to tensor\n","    transforms.append(\n","        T.LoadImaged(keys=['image', 'label'])\n","    )\n","\n","    # step 2: Add an extra \"channel\" dimension (pytorch/monai convention)\n","    transforms.append(\n","        T.EnsureChannelFirstd(keys=['image', 'label'])\n","    )\n","\n","    if is_train:\n","        # do any data augmentations here <-----------------\n","        ...\n","\n","\n","    # step 3: Resize the data to a uniform size\n","    transforms.append(\n","        T.ResizeD(keys=['image', 'label'], spatial_size=(n_pixels, n_pixels, n_pixels//2), mode=['bilinear', 'nearest'])\n","    )\n","\n","    # step 4: rescale the image intenisty between 0 and 1\n","    transforms.append(T.ScaleIntensityD(keys=['image']))\n","\n","    transform = T.Compose(transforms)\n","    return transform\n"],"metadata":{"id":"C-yCCEjtUzO8"},"id":"C-yCCEjtUzO8","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1CYH7e6rdrTJBQNp_JcrFL-XDLZfmnB3s","timestamp":1753118486494}],"gpuType":"T4","collapsed_sections":["zJ0GYiznpQjd"]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}